{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNe31gFjGuY12DUmY2aQrbk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anokhina-rgb/Google-Colabs/blob/main/mp3_transcriber_in_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fmQPMOSUwxD-",
        "outputId": "171871a9-8730-48e2-c112-f41c819c9bd8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'null' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3440978094.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     {\n\u001b[1;32m     18\u001b[0m       \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \"metadata\": {\n\u001b[1;32m     21\u001b[0m         \"colab\": {\n",
            "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
          ]
        }
      ],
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": []\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 1000\n",
        "        },\n",
        "        \"id\": \"9deJOasYCzCa\",\n",
        "        \"outputId\": \"1c6ceb34-da59-4851-c47d-1ec34365b452\"\n",
        "      },\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"\\u001b[?25l     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m0.0/803.2 kB\\u001b[0m \\u001b[31m?\\u001b[0m eta \\u001b[36m-:--:--\\u001b[0m\\r\\u001b[2K     \\u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m\\u001b[91m╸\\u001b[0m\\u001b[90m━━━━━━━━━━━━━\\u001b[0m \\u001b[32m522.2/803.2 kB\\u001b[0m \\u001b[31m15.2 MB/s\\u001b[0m eta \\u001b[36m0:00:01\\u001b[0m\\r\\u001b[2K     \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m803.2/803.2 kB\\u001b[0m \\u001b[31m14.5 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25h  Installing build dependencies ... \\u001b[?25l\\u001b[?25hdone\\n\",\n",
        "            \"  Getting requirements to build wheel ... \\u001b[?25l\\u001b[?25hdone\\n\",\n",
        "            \"  Preparing metadata (pyproject.toml) ... \\u001b[?25l\\u001b[?25hdone\\n\",\n",
        "            \"\\u001b[2K   \\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\u001b[0m \\u001b[32m253.0/253.0 kB\\u001b[0m \\u001b[31m19.0 MB/s\\u001b[0m eta \\u001b[36m0:00:00\\u001b[0m\\n\",\n",
        "            \"\\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \\u001b[?25l\\u001b[?25hdone\\n\",\n",
        "            \"Upload your MP3/WAV audio files (multiple selection allowed)\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"display_data\",\n",
        "          \"data\": {\n",
        "            \"text/plain\": [\n",
        "              \"<IPython.core.display.HTML object>\"\n",
        "            ],\n",
        "            \"text/html\": [\n",
        "              \"\\n\",\n",
        "              \"     <input type=\\\"file\\\" id=\\\"files-b9c0015b-862b-45c5-85e7-de12175bcf25\\\" name=\\\"files[]\\\" multiple disabled\\n\",\n",
        "              \"        style=\\\"border:none\\\" />\\n\",\n",
        "              \"     <output id=\\\"result-b9c0015b-862b-45c5-85e7-de12175bcf25\\\">\\n\",\n",
        "              \"      Upload widget is only available when the cell has been executed in the\\n\",\n",
        "              \"      current browser session. Please rerun this cell to enable.\\n\",\n",
        "              \"      </output>\\n\",\n",
        "              \"      <script>// Copyright 2017 Google LLC\\n\",\n",
        "              \"//\\n\",\n",
        "              \"// Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\\n\",\n",
        "              \"// you may not use this file except in compliance with the License.\\n\",\n",
        "              \"// You may obtain a copy of the License at\\n\",\n",
        "              \"//\\n\",\n",
        "              \"//      http://www.apache.org/licenses/LICENSE-2.0\\n\",\n",
        "              \"//\\n\",\n",
        "              \"// Unless required by applicable law or agreed to in writing, software\\n\",\n",
        "              \"// distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\n\",\n",
        "              \"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n\",\n",
        "              \"// See the License for the specific language governing permissions and\\n\",\n",
        "              \"// limitations under the License.\\n\",\n",
        "              \"\\n\",\n",
        "              \"/**\\n\",\n",
        "              \" * @fileoverview Helpers for google.colab Python module.\\n\",\n",
        "              \" */\\n\",\n",
        "              \"(function(scope) {\\n\",\n",
        "              \"function span(text, styleAttributes = {}) {\\n\",\n",
        "              \"  const element = document.createElement('span');\\n\",\n",
        "              \"  element.textContent = text;\\n\",\n",
        "              \"  for (const key of Object.keys(styleAttributes)) {\\n\",\n",
        "              \"    element.style[key] = styleAttributes[key];\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"  return element;\\n\",\n",
        "              \"}\\n\",\n",
        "              \"\\n\",\n",
        "              \"// Max number of bytes which will be uploaded at a time.\\n\",\n",
        "              \"const MAX_PAYLOAD_SIZE = 100 * 1024;\\n\",\n",
        "              \"\\n\",\n",
        "              \"function _uploadFiles(inputId, outputId) {\\n\",\n",
        "              \"  const steps = uploadFilesStep(inputId, outputId);\\n\",\n",
        "              \"  const outputElement = document.getElementById(outputId);\\n\",\n",
        "              \"  // Cache steps on the outputElement to make it available for the next call\\n\",\n",
        "              \"  // to uploadFilesContinue from Python.\\n\",\n",
        "              \"  outputElement.steps = steps;\\n\",\n",
        "              \"\\n\",\n",
        "              \"  return _uploadFilesContinue(outputId);\\n\",\n",
        "              \"}\\n\",\n",
        "              \"\\n\",\n",
        "              \"// This is roughly an async generator (not supported in the browser yet),\\n\",\n",
        "              \"// where there are multiple asynchronous steps and the Python side is going\\n\",\n",
        "              \"// to poll for completion of each step.\\n\",\n",
        "              \"// This uses a Promise to block the python side on completion of each step,\\n\",\n",
        "              \"// then passes the result of the previous step as the input to the next step.\\n\",\n",
        "              \"function _uploadFilesContinue(outputId) {\\n\",\n",
        "              \"  const outputElement = document.getElementById(outputId);\\n\",\n",
        "              \"  const steps = outputElement.steps;\\n\",\n",
        "              \"\\n\",\n",
        "              \"  const next = steps.next(outputElement.lastPromiseValue);\\n\",\n",
        "              \"  return Promise.resolve(next.value.promise).then((value) => {\\n\",\n",
        "              \"    // Cache the last promise value to make it available to the next\\n\",\n",
        "              \"    // step of the generator.\\n\",\n",
        "              \"    outputElement.lastPromiseValue = value;\\n\",\n",
        "              \"    return next.value.response;\\n\",\n",
        "              \"  });\\n\",\n",
        "              \"}\\n\",\n",
        "              \"\\n\",\n",
        "              \"/**\\n\",\n",
        "              \" * Generator function which is called between each async step of the upload\\n\",\n",
        "              \" * process.\\n\",\n",
        "              \" * @param {string} inputId Element ID of the input file picker element.\\n\",\n",
        "              \" * @param {string} outputId Element ID of the output display.\\n\",\n",
        "              \" * @return {!Iterable<!Object>} Iterable of next steps.\\n\",\n",
        "              \" */\\n\",\n",
        "              \"function* uploadFilesStep(inputId, outputId) {\\n\",\n",
        "              \"  const inputElement = document.getElementById(inputId);\\n\",\n",
        "              \"  inputElement.disabled = false;\\n\",\n",
        "              \"\\n\",\n",
        "              \"  const outputElement = document.getElementById(outputId);\\n\",\n",
        "              \"  outputElement.innerHTML = '';\\n\",\n",
        "              \"\\n\",\n",
        "              \"  const pickedPromise = new Promise((resolve) => {\\n\",\n",
        "              \"    inputElement.addEventListener('change', (e) => {\\n\",\n",
        "              \"      resolve(e.target.files);\\n\",\n",
        "              \"    });\\n\",\n",
        "              \"  });\\n\",\n",
        "              \"\\n\",\n",
        "              \"  const cancel = document.createElement('button');\\n\",\n",
        "              \"  inputElement.parentElement.appendChild(cancel);\\n\",\n",
        "              \"  cancel.textContent = 'Cancel upload';\\n\",\n",
        "              \"  const cancelPromise = new Promise((resolve) => {\\n\",\n",
        "              \"    cancel.onclick = () => {\\n\",\n",
        "              \"      resolve(null);\\n\",\n",
        "              \"    };\\n\",\n",
        "              \"  });\\n\",\n",
        "              \"\\n\",\n",
        "              \"  // Wait for the user to pick the files.\\n\",\n",
        "              \"  const files = yield {\\n\",\n",
        "              \"    promise: Promise.race([pickedPromise, cancelPromise]),\\n\",\n",
        "              \"    response: {\\n\",\n",
        "              \"      action: 'starting',\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"  };\\n\",\n",
        "              \"\\n\",\n",
        "              \"  cancel.remove();\\n\",\n",
        "              \"\\n\",\n",
        "              \"  // Disable the input element since further picks are not allowed.\\n\",\n",
        "              \"  inputElement.disabled = true;\\n\",\n",
        "              \"\\n\",\n",
        "              \"  if (!files) {\\n\",\n",
        "              \"    return {\\n\",\n",
        "              \"      response: {\\n\",\n",
        "              \"        action: 'complete',\\n\",\n",
        "              \"      }\\n\",\n",
        "              \"    };\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  for (const file of files) {\\n\",\n",
        "              \"    const li = document.createElement('li');\\n\",\n",
        "              \"    li.append(span(file.name, {fontWeight: 'bold'}));\\n\",\n",
        "              \"    li.append(span(\\n\",\n",
        "              \"        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\\n\",\n",
        "              \"        `last modified: ${\\n\",\n",
        "              \"            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\\n\",\n",
        "              \"                                    'n/a'} - `));\\n\",\n",
        "              \"    const percent = span('0% done');\\n\",\n",
        "              \"    li.appendChild(percent);\\n\",\n",
        "              \"\\n\",\n",
        "              \"    outputElement.appendChild(li);\\n\",\n",
        "              \"\\n\",\n",
        "              \"    const fileDataPromise = new Promise((resolve) => {\\n\",\n",
        "              \"      const reader = new FileReader();\\n\",\n",
        "              \"      reader.onload = (e) => {\\n\",\n",
        "              \"        resolve(e.target.result);\\n\",\n",
        "              \"      };\\n\",\n",
        "              \"      reader.readAsArrayBuffer(file);\\n\",\n",
        "              \"    });\\n\",\n",
        "              \"    // Wait for the data to be ready.\\n\",\n",
        "              \"    let fileData = yield {\\n\",\n",
        "              \"      promise: fileDataPromise,\\n\",\n",
        "              \"      response: {\\n\",\n",
        "              \"        action: 'continue',\\n\",\n",
        "              \"      }\\n\",\n",
        "              \"    };\\n\",\n",
        "              \"\\n\",\n",
        "              \"    // Use a chunked sending to avoid message size limits. See b/62115660.\\n\",\n",
        "              \"    let position = 0;\\n\",\n",
        "              \"    do {\\n\",\n",
        "              \"      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\\n\",\n",
        "              \"      const chunk = new Uint8Array(fileData, position, length);\\n\",\n",
        "              \"      position += length;\\n\",\n",
        "              \"\\n\",\n",
        "              \"      const base64 = btoa(String.fromCharCode.apply(null, chunk));\\n\",\n",
        "              \"      yield {\\n\",\n",
        "              \"        response: {\\n\",\n",
        "              \"          action: 'append',\\n\",\n",
        "              \"          file: file.name,\\n\",\n",
        "              \"          data: base64,\\n\",\n",
        "              \"        },\\n\",\n",
        "              \"      };\\n\",\n",
        "              \"\\n\",\n",
        "              \"      let percentDone = fileData.byteLength === 0 ?\\n\",\n",
        "              \"          100 :\\n\",\n",
        "              \"          Math.round((position / fileData.byteLength) * 100);\\n\",\n",
        "              \"      percent.textContent = `${percentDone}% done`;\\n\",\n",
        "              \"\\n\",\n",
        "              \"    } while (position < fileData.byteLength);\\n\",\n",
        "              \"  }\\n\",\n",
        "              \"\\n\",\n",
        "              \"  // All done.\\n\",\n",
        "              \"  yield {\\n\",\n",
        "              \"    response: {\\n\",\n",
        "              \"      action: 'complete',\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"  };\\n\",\n",
        "              \"}\\n\",\n",
        "              \"\\n\",\n",
        "              \"scope.google = scope.google || {};\\n\",\n",
        "              \"scope.google.colab = scope.google.colab || {};\\n\",\n",
        "              \"scope.google.colab._files = {\\n\",\n",
        "              \"  _uploadFiles,\\n\",\n",
        "              \"  _uploadFilesContinue,\\n\",\n",
        "              \"};\\n\",\n",
        "              \"})(self);\\n\",\n",
        "              \"</script> \"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {}\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Saving 09.02.01-student-conversation-directons-and-questions.mp3 to 09.02.01-student-conversation-directons-and-questions.mp3\\n\",\n",
        "            \"Saving 09.03.03-student-conversation.mp3 to 09.03.03-student-conversation.mp3\\n\",\n",
        "            \"Saving 09.03.04-student-conversation.mp3 to 09.03.04-student-conversation.mp3\\n\",\n",
        "            \"Saving 2025-07-17-121245_173642.mp3 to 2025-07-17-121245_173642.mp3\\n\",\n",
        "            \"Saving celebrity short answer.mp3 to celebrity short answer.mp3\\n\",\n",
        "            \"Saving leaders.mp3 to leaders.mp3\\n\",\n",
        "            \"Saving leaders1.mp3 to leaders1.mp3\\n\",\n",
        "            \"Saving photo_2025-06-04_12-05-51.jpg to photo_2025-06-04_12-05-51.jpg\\n\",\n",
        "            \"Saving photo_2025-06-23_17-29-12.jpg to photo_2025-06-23_17-29-12.jpg\\n\",\n",
        "            \"Saving response 100 words 2025-07-17-121534_190519.mp3 to response 100 words 2025-07-17-121534_190519.mp3\\n\",\n",
        "            \"Saving social media.mp3 to social media.mp3\\n\",\n",
        "            \"Saving speaking.mp3 to speaking.mp3\\n\",\n",
        "            \"Saving teachers vs computers.mp3 to teachers vs computers.mp3\\n\",\n",
        "            \"Saving voice_file_to_txt_transcriber_by_whisper_in_google_colab.ipynb to voice_file_to_txt_transcriber_by_whisper_in_google_colab.ipynb\\n\",\n",
        "            \"Saving writing.mp3 to writing.mp3\\n\",\n",
        "            \"Saving Відео WhatsApp, дата_ 2025-08-21 о 18.03.17_a7a28209.mp4 to Відео WhatsApp, дата_ 2025-08-21 о 18.03.17_a7a28209.mp4\\n\",\n",
        "            \"Saving Відео WhatsApp, дата_ 2025-08-21 о 18.03.18_0863234b.mp4 to Відео WhatsApp, дата_ 2025-08-21 о 18.03.18_0863234b.mp4\\n\",\n",
        "            \"Loading Whisper model...\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"100%|███████████████████████████████████████| 461M/461M [00:08<00:00, 57.0MiB/s]\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Model loaded.\\n\",\n",
        "            \"\\n\",\n",
        "            \"[1/17] Transcribing: 09.02.01-student-conversation-directons-and-questions.mp3\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\\n\",\n",
        "            \"  warnings.warn(\\\"FP16 is not supported on CPU; using FP32 instead\\\")\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"✅ Completed: 09.02.01-student-conversation-directons-and-questions.mp3\\n\",\n",
        "            \"[2/17] Transcribing: 09.03.03-student-conversation.mp3\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\\n\",\n",
        "            \"  warnings.warn(\\\"FP16 is not supported on CPU; using FP32 instead\\\")\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"✅ Completed: 09.03.03-student-conversation.mp3\\n\",\n",
        "            \"[3/17] Transcribing: 09.03.04-student-conversation.mp3\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\\n\",\n",
        "            \"  warnings.warn(\\\"FP16 is not supported on CPU; using FP32 instead\\\")\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"✅ Completed: 09.03.04-student-conversation.mp3\\n\",\n",
        "            \"[4/17] Transcribing: 2025-07-17-121245_173642.mp3\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\\n\",\n",
        "            \"  warnings.warn(\\\"FP16 is not supported on CPU; using FP32 instead\\\")\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"✅ Completed: 2025-07-17-121245_173642.mp3\\n\",\n",
        "            \"[5/17] Transcribing: celebrity short answer.mp3\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\\n\",\n",
        "            \"  warnings.warn(\\\"FP16 is not supported on CPU; using FP32 instead\\\")\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"✅ Completed: celebrity short answer.mp3\\n\",\n",
        "            \"[6/17] Transcribing: leaders.mp3\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\\n\",\n",
        "            \"  warnings.warn(\\\"FP16 is not supported on CPU; using FP32 instead\\\")\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"✅ Completed: leaders.mp3\\n\",\n",
        "            \"[7/17] Transcribing: leaders1.mp3\\n\"\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stderr\",\n",
        "          \"text\": [\n",
        "            \"/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\\n\",\n",
        "            \"  warnings.warn(\\\"FP16 is not supported on CPU; using FP32 instead\\\")\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ],\n",
        "      \"source\": [\n",
        "        \"# Install dependencies\\n\",\n",
        "        \"!pip install openai-whisper python-docx --quiet\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Imports\\n\",\n",
        "        \"import whisper\\n\",\n",
        "        \"from docx import Document\\n\",\n",
        "        \"from google.colab import files\\n\",\n",
        "        \"import os\\n\",\n",
        "        \"from datetime import datetime\\n\",\n",
        "        \"\\n\",\n",
        "        \"# --- Helper functions ---\\n\",\n",
        "        \"def save_word(text, path):\\n\",\n",
        "        \"    doc = Document()\\n\",\n",
        "        \"    doc.add_paragraph(text)\\n\",\n",
        "        \"    doc.save(path)\\n\",\n",
        "        \"\\n\",\n",
        "        \"def download_file(path):\\n\",\n",
        "        \"    files.download(path)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# --- Upload audio files ---\\n\",\n",
        "        \"print(\\\"Upload your MP3/WAV audio files (multiple selection allowed)\\\")\\n\",\n",
        "        \"uploaded = files.upload()  # Opens file picker\\n\",\n",
        "        \"\\n\",\n",
        "        \"audio_files = list(uploaded.keys())\\n\",\n",
        "        \"if not audio_files:\\n\",\n",
        "        \"    raise SystemExit(\\\"No files uploaded.\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# --- Load Whisper model ---\\n\",\n",
        "        \"print(\\\"Loading Whisper model...\\\")\\n\",\n",
        "        \"model = whisper.load_model(\\\"small\\\")  # You can change to base/medium/large\\n\",\n",
        "        \"print(\\\"Model loaded.\\\\n\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# --- Create folder for outputs ---\\n\",\n",
        "        \"output_folder = \\\"transcriptions_colab\\\"\\n\",\n",
        "        \"os.makedirs(output_folder, exist_ok=True)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# --- Transcribe each file ---\\n\",\n",
        "        \"for idx, file in enumerate(audio_files, start=1):\\n\",\n",
        "        \"    print(f\\\"[{idx}/{len(audio_files)}] Transcribing: {file}\\\")\\n\",\n",
        "        \"    try:\\n\",\n",
        "        \"        result = model.transcribe(file)\\n\",\n",
        "        \"        text = result['text'].strip()\\n\",\n",
        "        \"\\n\",\n",
        "        \"        # Save TXT\\n\",\n",
        "        \"        txt_filename = os.path.join(output_folder, f\\\"{os.path.splitext(file)[0]}.txt\\\")\\n\",\n",
        "        \"        with open(txt_filename, \\\"w\\\", encoding=\\\"utf-8\\\") as f:\\n\",\n",
        "        \"            f.write(text)\\n\",\n",
        "        \"\\n\",\n",
        "        \"        # Save DOCX\\n\",\n",
        "        \"        docx_filename = os.path.join(output_folder, f\\\"{os.path.splitext(file)[0]}.docx\\\")\\n\",\n",
        "        \"        save_word(text, docx_filename)\\n\",\n",
        "        \"\\n\",\n",
        "        \"        print(f\\\"✅ Completed: {file}\\\")\\n\",\n",
        "        \"    except Exception as e:\\n\",\n",
        "        \"        print(f\\\"❌ Error transcribing {file}: {e}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# --- Zip the output folder ---\\n\",\n",
        "        \"import shutil\\n\",\n",
        "        \"zip_filename = f\\\"transcriptions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\\\"\\n\",\n",
        "        \"shutil.make_archive(zip_filename.replace('.zip',''), 'zip', output_folder)\\n\",\n",
        "        \"print(f\\\"\\\\nAll transcriptions zipped as: {zip_filename}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# --- Download ZIP ---\\n\",\n",
        "        \"files.download(zip_filename)\\n\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    }
  ]
}